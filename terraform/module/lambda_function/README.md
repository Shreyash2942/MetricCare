# ðŸ§© AWS Lambda Function Module

This module provisions an **AWS Lambda function** that orchestrates the MetricCare ETL workflow by triggering **AWS Glue Workflows** whenever new data is uploaded to S3 or on a scheduled basis via EventBridge.  
The Lambda function acts as the **automation brain** of the data lakehouse, connecting event-driven and scheduled pipelines.

---

## ðŸ“– Overview

| Component | Purpose |
|------------|----------|
| **Lambda Function** | Executes orchestration logic (e.g., start Glue Workflow). |
| **IAM Role & Policies** | Grants Lambda permission to invoke Glue, access S3, and read logs. |
| **Environment Variables** | Configurable parameters like workflow name, environment, and bucket. |
| **S3 Source** | Stores the Lambda deployment package (ZIP) uploaded via Terraform. |

---

## ðŸ§© Use Case in MetricCare Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        New Data        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       Starts        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     S3     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   Lambda     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   Glue Job   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²                                     â”‚
       â”‚                                     â–¼
       â”‚                          Sends alerts via SNS/EventBridge
       â”‚
   (FHIR JSON Upload)
```

- **S3 â†’ Lambda:** Triggered by new data uploads.  
- **Lambda â†’ Glue:** Starts Glue Workflow (Bronze â†’ Silver â†’ Gold ETL).  
- **EventBridge â†’ Lambda:** Executes scheduled workflow runs.  
- **Lambda â†’ SNS:** Sends job status or error alerts.

---

## ðŸ—‚ï¸ Module Structure

```bash
lambda_function/
â”œâ”€â”€ main.tf         # Defines Lambda function, IAM role, and environment variables
â”œâ”€â”€ variables.tf    # Input variables (function name, handler, runtime, etc.)
â””â”€â”€ outputs.tf      # Exports Lambda ARN and IAM role
```

---

## âš™ï¸ Example Usage

Below is an example of how to call this module in your Terraform root:

```hcl
module "lambda_function" {
  source              = "./module/lambda_function"
  function_name       = "metriccare_trigger_glue"
  handler             = "myglueworkflow.myglueworkflow"
  runtime             = "python3.12"
  s3_bucket           = var.lambda_script_bucket
  s3_key              = "lambda/myglueworkflow.zip"
  environment = {
    GLUE_WORKFLOW_NAME = "hudi_to_silver_shreyash"
    LOG_LEVEL          = "INFO"
  }
  timeout             = 60
  memory_size         = 256
  tags = {
    Environment = terraform.workspace
    Project     = "MetricCare"
  }
}
```

> âš¡ Make sure the Lambda deployment ZIP file is uploaded to S3 before running `terraform apply`.

---

## ðŸ”‘ Key Variables

| Variable | Description | Type | Default |
|-----------|--------------|------|----------|
| `function_name` | Name of the Lambda function. | `string` | `"metriccare_trigger_glue"` |
| `handler` | Entry point (e.g., `file_name.handler_function`). | `string` | `"lambda_function.lambda_handler"` |
| `runtime` | Lambda runtime environment. | `string` | `"python3.12"` |
| `s3_bucket` | S3 bucket containing the Lambda ZIP file. | `string` | `null` |
| `s3_key` | Key (path) to the Lambda ZIP in S3. | `string` | `null` |
| `timeout` | Timeout (in seconds) for the function. | `number` | `60` |
| `memory_size` | Memory allocation for Lambda. | `number` | `256` |
| `environment` | Map of environment variables passed to Lambda. | `map(string)` | `{}` |
| `tags` | Common tags applied to resources. | `map(string)` | `{}` |

---

## ðŸ“¤ Outputs

| Output | Description |
|---------|--------------|
| `lambda_arn` | ARN of the created Lambda function. |
| `lambda_name` | Name of the function. |
| `lambda_role_arn` | IAM Role ARN associated with the Lambda function. |

---

## ðŸ§  Best Practices

- Use **versioned ZIP deployments** to maintain reproducibility.  
- Store all Lambda scripts in a dedicated S3 prefix (`upload_scripts/`).  
- Grant **least-privilege IAM policies** â€” only Glue, S3, and CloudWatch Logs access.  
- Enable **CloudWatch logging** for observability.  
- Keep **timeout < 5 minutes**; Glue handles long ETL operations.  
- Use **environment variables** for workflow names instead of hardcoding them.

---

## ðŸ§© Testing the Module

To validate deployment:

```bash
terraform init
terraform apply -target=module.lambda_function -auto-approve
```

Then verify:

- In AWS Console â†’ Lambda â†’ **metriccare_trigger_glue**
- Check **Environment variables** and **Execution role**.
- Trigger test events manually from S3 or EventBridge.

---

## ðŸ§© Example Lambda Script Reference

The associated Python script (uploaded via S3) might look like this:

```python
import boto3
import os

glue = boto3.client("glue")

def lambda_handler(event, context):
    workflow_name = os.environ["GLUE_WORKFLOW_NAME"]
    print(f"Starting Glue Workflow: {workflow_name}")
    glue.start_workflow_run(Name=workflow_name)
    return {"status": "Workflow Triggered"}
```

---

## ðŸ”— References

- [Terraform AWS Lambda Resource](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function)  
- [Terraform Lambda Permissions](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_permission)  
- [AWS Lambda Developer Guide](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)  
- [AWS Glue Workflow Integration](https://docs.aws.amazon.com/glue/latest/dg/orchestrate-workflow.html)  
- [EventBridge and Lambda Integration](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-targets-lambda.html)

---

> ðŸ§± **Author:** Shreyash (Data Engineer)  
> ðŸ“š *MetricCare â€“ AWS Data Lakehouse for Healthcare Analytics*  
> ðŸ”— *Module: lambda_function â€“ Event-Driven Orchestration for Glue Workflows*
