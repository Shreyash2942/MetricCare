# ðŸ“¤ AWS S3 Upload Scripts Module

This module automates the upload of **Lambda and Glue job scripts** to the designated S3 bucket used in the MetricCare Data Lakehouse.  
It ensures all ETL and orchestration scripts are versioned, environment-specific, and available for deployment through Terraform workflows.

---

## ðŸ“– Overview

| Component | Purpose |
|------------|----------|
| **Lambda Scripts** | Python functions that trigger Glue workflows or monitor S3 events. |
| **Glue Scripts** | PySpark ETL scripts responsible for transforming and loading healthcare data. |
| **S3 Upload Automation** | Uploads all necessary script files to S3 as part of the Terraform apply process. |

---

## ðŸ§© Use Case in MetricCare Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Local Scripts     â”‚
â”‚ (Lambda + Glue)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Terraform Module   â”‚  â†’ Uploads â†’  S3: upload_scripts/
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWS Glue + Lambda  â”‚ â† Reads from â†’ S3 paths
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Terraform â†’ S3:** Uploads scripts to the specified S3 bucket during infrastructure provisioning.  
- **Lambda / Glue:** Fetches the latest script version from S3 at runtime.  

---

## ðŸ—‚ï¸ Module Structure

```bash
upload_scripts/
â”œâ”€â”€ main.tf         # Uses aws_s3_object to upload files to S3
â”œâ”€â”€ variables.tf    # Input variables for source and destination paths
â””â”€â”€ outputs.tf      # Exports uploaded object keys and locations
```

---

## âš™ï¸ Example Usage

Hereâ€™s an example configuration from your Terraform root module:

```hcl
module "upload_scripts" {
  source = "./module/s3/upload_scripts"

  bucket_name = "metriccare-upload-scripts"
  upload_file = {
    lambda_trigger = {
      s3_location     = "lambda/myglueworkflow.zip"
      source_location = "../lambda/myglueworkflow.zip"
    }
    glue_bronze = {
      s3_location     = "glue/scripts/bronze_etl.py"
      source_location = "../glue_job/scripts/bronze_etl.py"
    }
    glue_silver = {
      s3_location     = "glue/scripts/silver_etl.py"
      source_location = "../glue_job/scripts/silver_etl.py"
    }
    glue_gold = {
      s3_location     = "glue/scripts/gold_etl.py"
      source_location = "../glue_job/scripts/gold_etl.py"
    }
  }

  tags = {
    Environment = terraform.workspace
    Project     = "MetricCare"
  }
}
```

> ðŸ§© This module ensures your Lambda and Glue jobs always use the **latest uploaded script versions** during deployment.

---

## ðŸ”‘ Key Variables

| Variable | Description | Type | Default |
|-----------|--------------|------|----------|
| `bucket_name` | Target S3 bucket for uploading files. | `string` | n/a |
| `upload_file` | Map of files to upload (S3 key + local source path). | `map(object({ s3_location = string, source_location = string }))` | `{}` |
| `tags` | Resource tags for all uploaded objects. | `map(string)` | `{}` |

---

## ðŸ“¤ Outputs

| Output | Description |
|---------|--------------|
| `uploaded_files` | List of successfully uploaded S3 object keys. |
| `bucket_name` | Name of the target bucket where files were uploaded. |

---

## ðŸ§  Best Practices

- Keep **script paths consistent** (`lambda/`, `glue/scripts/`).  
- Maintain **versioned ZIPs or scripts** for traceability.  
- Use Terraform **workspaces** for environment isolation (e.g., dev/prod).  
- Validate the `source_location` path before apply to prevent broken uploads.  
- Enable **S3 versioning** on the upload bucket to retain script history.  

---

## ðŸ§© Testing the Module

Run the module independently to verify file uploads:

```bash
terraform init
terraform apply -target=module.upload_scripts -auto-approve
```

Verification steps:
1. Open **AWS S3 Console â†’ metriccare-upload-scripts**.  
2. Confirm files exist under the correct prefixes (`lambda/`, `glue/scripts/`).  
3. Check versioning and metadata tags.  

---

## ðŸ”— References

- [Terraform AWS S3 Object Resource](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_object)  
- [AWS S3 Console](https://console.aws.amazon.com/s3/)  
- [AWS Glue Documentation](https://docs.aws.amazon.com/glue/latest/dg/what-is-glue.html)  
- [AWS Lambda Documentation](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)

---

> ðŸ§± **Author:** Shreyash (Data Engineer)  
> ðŸ“š *MetricCare â€“ AWS Data Lakehouse for Healthcare Analytics*  
> ðŸ”— *Module: upload_scripts â€“ Automated Script Deployment for Glue & Lambda*
